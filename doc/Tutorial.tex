\documentclass[11pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\usepackage{fancyvrb}
\usepackage{color}
\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}

\newcommand\codeHighlight[1]{\textcolor[rgb]{1,0,0}{\textbf{#1}}}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Cortex Tutorial}
\author{Ricardo H. Ram’rez-Gonz‡lez, Mario Caccamo}
%\date{}                                           % Activate to display a given date or no date

\begin{document}
\maketitle

\section{Tutorial files}
This tutorial is based on two files. 

\begin{description}
\item[E. Coli. Reference] The complete reference genome of Escherichia coli str. K-12 substr. MG1655  (Accession U00096.2 )saved as \texttt{ecoli.fasta}. Note that any small reference genome can be used instead. 
\item[E. Coli. Samples] The illumina runs stored with accession number SRR001666 named as \texttt{SRR001666\_1.fastq} and \texttt{SRR001666\_2.fastq.} This dataset is paired end with an insert site of 500bp
\end{description}



\section{Compiling cortex}

Inside the cortex

\begin{Verbatim}[commandchars=\\\{\}]
$ make MAXK=\codeHighlight{31}
\end{Verbatim}

MAXK can be 31, 63 or 95. 
That is the maximum k-mer size that the specific compilation of cortex will use.

Cortex is designed to run on 64-bits machines, however it is possible to compile it on 32 bits machines with the flag 32\_BITS=1

\begin{Verbatim}[commandchars=\\\{\}]
$ make MAXK=31 \codeHighlight{ 32\_BITS=1}
\end{Verbatim}

To enable the use of read pairs, the flag ENABLE\_READ\_PAIRS=1

\begin{Verbatim}[commandchars=\\\{\}]
$ make MAXK=31 \codeHighlight{ENABLE\_READ\_PAIRS=1}
\end{Verbatim}

Please note that currently Cortex only compiles with compilers that allow nested functions. It has been tested with GCC 4.2.*. 

\section{Simple assembly on reference genome}

To test if cortex is running, we will load the E.Coli. reference into cortex and just output the contigs. 
\begin{enumerate}
\item Create a text file with the path to \texttt{ecoli.fasta} and name it \texttt{ecoli\_reference.txt}
\item  Execute cortex as follows:
\begin{Verbatim}
cortex_con_31 
	--input_format fasta 
	--input ecoli_reference.txt 
	--mem_height 16 
	--kmer_size 27 
	--output_supernodes supernodes.fa
\end{Verbatim}
\end{enumerate}

\subsection{To think about...}

\begin{enumerate}
\item How many sequences does the reference file has?  %1
\item How many sequences does supernodes.fa has? %504
\item Is there any reason for the difference? %repeats smaller than the kmer size. 
\item What happens when you increase the kmer size to 31, or 63? %The number of sequences drops
\end{enumerate}

For each file of contigs created in the tutorial think about:
\begin{itemize}
\item The amount of assembled sequence
\item The N50. 
\item The number of contigs. 
\end{itemize}
Beware, this is not a comprehensive list of quality metrics, but are enough to give a rough idea. 


%TODO: Explain a bit of what is memheight

\section {A more realistic example}
Now, we will assemble the illumina sample dataset.  We had printed the the contigs without any ambiguity only once. Now we will output contigs which are still reliable, printing different flanking sequences to a repetitive  region.  %TODO: improve the wording. 

\begin{enumerate}
\item Create a text file with the paths to \texttt{SRR001666\_1.fastq} and \texttt{SRR001666\_2.fastq.}, each path in its own line. Save it as \texttt{ecoli\_samples.txt}
\item create the graph and store it as it is in memory. 
\begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31 
	--input_format fastq 
	--input ecoli_samples.txt
	--mem_height 18  
	--kmer_size  27 
	\codeHighlight{--hash_output_file ecoli_from_reads1.mem}
\end{Verbatim}
\item Load the graph in to memory and print the supernodes. 
\begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31
	 --input_format hash 
	 \codeHighlight{--input ecoli_from_reads1.mem} 
	 --output_contigs sample_supernedes.fa
\end{Verbatim}
\end{enumerate}

\subsection{Cleaning}
So far ,we had assembled all the reads bases in the raw files. However, the reads always contain noise and we need to clean them. The following commands show how the cleaning can be done. 

\subsubsection{Clp tipping}
As the end of the read is more prone to have sequencing errors, some paths in the graph may be completely disconnected. If the path is short enough, it can be removed. In the following example, the minimum length a tip can have to be real is 100 kmers. 
\begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31
	 --input_format hash 
	 \codeHighlight{--tip_clip 100}
	 --input ecoli_from_reads1.mem 
	 --output_contigs sample_tc100_supernedes.fa
\end{Verbatim}


\subsubsection{Remove low coverage supernodes}
A chimeric read or a sequencing error  could potentially lead to paths joining two different contigs. To reduce the chances of this happening, 
\begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31
	 --input_format hash 
	 \codeHighlight{--remove_low_coverage_supernodes 1}
	 --input ecoli_from_reads1.mem 
	 --output_contigs sample_tc100_supernedes.fa
\end{Verbatim}


\subsubsection{Remove bubbles}
A single base error or a SNP  lead to a bubble shaped structure in the graph. If the aim is to find a consensus sequence, removing the bubbles extend the length of the contigs. 

\begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31
	 --input_format hash 
	 \codeHighlight{--remove_bubbles}
	 --input ecoli_from_reads1.mem 
	 --output_contigs sample_rb_supernedes.fa
\end{Verbatim}

%\subsubsection{Remove spurious edges}
%TODO: Ask Mario/Richard more about this flag. 


\section{Large genomes}
%Create CTX for eachlane
%Create multiple CTXs for the read. 
One way to speed up the assembly process and to cope with a large amount of reads is to create the graph for each fastq file and merge them at a later stage.

\begin{enumerate}
 \item Create a file with the path to  \texttt{SRR001666\_1.fastq} called  \texttt{ecoli\_sample1.txt}
 \item Create a binary file just for  \texttt{SRR001666\_1.fastq} using the flag \texttt{--dump\_binary}
  \begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31 
	--input_format fastq 
	--input ecoli_sample1.txt 
        --mem_height 18  
        --kmer_size  27  
        \codeHighlight{--dump_binary ecoli_from_reads1.ctx}
  \end{Verbatim}
 \item Repeat 1 and 2 with the reads from \texttt{SRR001666\_2.fastq}
 \item Create a file with the file to both \texttt{ctx} files. 
 \begin{Verbatim}[commandchars=\\\{\}]
cortex_con_31 
        \codeHighlight{--input_format binary} 
        --input ecoli_ctx_both_samples.txt 
        --mem_height 19 
        --kmer_size 27 
        \codeHighlight{--hash_output_file ecoli_from_reads.mem}
        \codeHighlight{--dump_binary ecoli_from_reads.ctx}
        --output_supernodes contigs_from_reads.fa 
  \end{Verbatim}	  
\end{enumerate}

Note that you can either dump to a new ctx if you want to keep adding kmers, to a hash file, if you don't want to keep adding files. This strategy can be used to do a partial clean when you have memory constrains too. 


\section{Large genomes with huge coverage}

When dealing with datasets larger than your infrastructure can deal in a reasonable time, it is possible to do a divide and conquer strategy. This is specially useful when dealing with the HiSeq platform where the fastq files are significantly larger than on the previous generation. 

\begin{enumerate}
\item Create a file of files with the sections of the fastq you want to assemble. 
 \begin{Verbatim}[commandchars=\\\{\}]
 scripts/util/build_cortex_entries.pl both_lanes.txt 4 mini_lanes
\end{Verbatim}	
\item 
\end{enumerate}


 \begin{Verbatim}[commandchars=\\\{\}]
for i in  \{1..8\} ; do 
./release_1.0.1/bin/cortex_con_31 
        --input_format fastq 
        --input mini_lanes.$i 
        --mem_height 17 
        --kmer_size  27 
        --dump_binary ecoli_mini_$i.ctx
done;
 \end{Verbatim}	

\section{FAQ}

\subsection{What is the difference between the hash and binary formats?}
The hash format is a dump of the whole graph, you can't modify it's settings. It is used when you had readed all the input files and you just want to see the impact of different cleaning or printing algorithms. 
The binary format stores all the kmers only once, however you can merge different binary files to get the full graph. This is slower to load, but it gives you the flexibility to make an incremental load of reads. 


%\subsection{Read Pairs}



\end{document}  
